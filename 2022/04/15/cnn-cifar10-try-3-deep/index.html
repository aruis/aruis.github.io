<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>通过加深网络把CIFAR10的训练精度提升到80% | 槛槛之间，点点滴滴</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/css/dark.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script src="https://www.googletagmanager.com/gtag/js?id=G-DP2NRWYLHE" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'G-DP2NRWYLHE');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'cb57d6270614f565f1d62009fe3ef740';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><div class="darkmode-toggle">🌓</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.1.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">通过加深网络把CIFAR10的训练精度提升到80%</h1><a id="logo" href="/.">槛槛之间，点点滴滴</a><p class="description">牧云踏歌的博客，企图做个槛外人，但其实不过在槛槛之间徘徊罢了</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">通过加深网络把CIFAR10的训练精度提升到80%</h1><div class="post-meta">2022-04-15<span> | </span><span class="category"><a href="/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/">程序人生</a></span></div><a class="disqus-comment-count" href="/2022/04/15/cnn-cifar10-try-3-deep/#vcomment"><span class="waline-comment-count" id="/2022/04/15/cnn-cifar10-try-3-deep/"></span><span> 条评论</span></a><div class="post-content"><p>这次继续，在原来网络的基础上，加深了卷积层的数量，从原来的3层卷积，加深到了6层。核心代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p><img src="/media/CleanShot%202022-04-15%20at%2013.52.32.png" alt="CleanShot 2022-04-15 at 13.52.32"></p>
<p>可以看到验证精度比之前的略好一些。但是程度非常有限，刚刚有接近<code>80%</code>的影子。下面我尝试增加<code>Dropout</code>层：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>
<p>在原来的基础上增加了两层<code>Dropout</code>，结果点进一步得到改善：</p>
<p><img src="/media/CleanShot%202022-04-15%20at%2013.57.20.png" alt="CleanShot 2022-04-15 at 13.57.20"></p>
<p>已经达到<code>80%</code>的水平了。</p>
<hr>
<p>到这之后，我又发现一个自己代码的问题，之前修改代码的时候，去掉了最后卷积层之后的池化层，肯定是不妥的。我现在给加回来：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dense(<span class="number">512</span>, activation=<span class="string">&#x27;relu&#x27;</span>))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.5</span>))</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br></pre></td></tr></table></figure>

<p>重新训练结果如下：</p>
<p><img src="/media/CleanShot%202022-04-15%20at%2014.22.21.png" alt="CleanShot 2022-04-15 at 14.22.21"></p>
<p>可以看到验证精度最后都能超过<code>80%</code>。只能说怪我了，卷积层后面不跟池化层的话数据就太大了，用池化层压缩一下，训练效果往往会更好。</p>
<p>下面我又尝试把<code>Flatten</code>之后的全连接层给去掉，得到了更好的数据：</p>
<p><img src="/media/CleanShot%202022-04-15%20at%2014.40.38.png" alt="CleanShot 2022-04-15 at 14.40.38"></p>
<p>训练在<code>12</code>轮之后，验证精度就稳步在<code>80%</code>以上了。<br>最终代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line"></span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br><span class="line"></span><br><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;Adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">history = model.fit(train_images, train_labels, epochs=<span class="number">50</span>, batch_size=<span class="number">64</span>,validation_data=(test_images, test_labels))</span><br></pre></td></tr></table></figure></div><div class="post-copyright"><script type="text/javascript" src="/js/copyright.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copyright.css"><p><span>本文标题：</span>通过加深网络把CIFAR10的训练精度提升到80%</p><p><span>文章作者：</span>牧云踏歌</p><p><span>发布时间：</span>2022-04-15</p><p><span>最后更新：</span>2022-04-15</p><p><span>原始链接：</span><a href="/2022/04/15/cnn-cifar10-try-3-deep/">http://www.kankanzhijian.com/2022/04/15/cnn-cifar10-try-3-deep/</a><span class="copy-path"><i class="fa fa-clipboard" data-clipboard-text="http://www.kankanzhijian.com/2022/04/15/cnn-cifar10-try-3-deep/"></i></span></p><p><span>版权声明：</span>本博客文章均系本人原创，转载请注名出处</p></div><br><div class="tags"><a href="/tags/Keras/"><i class="fa fa-tag"></i>Keras</a><a href="/tags/DeepLearning/"><i class="fa fa-tag"></i>DeepLearning</a></div><div class="post-nav"><a class="pre" href="/2022/04/18/disable-metal-gpu-on-apple-silicon/">在Apple Silicon上关闭M1的GPU，仅用CPU进行Tensorflow训练</a><a class="next" href="/2022/04/14/cnn-cifar10-try-2/">使用简单的CNN训练CIFAR10，理解padding='same'的含义</a></div><div id="waline"></div><script src="https://cdn.jsdelivr.net/npm/@waline/client"></script><script>Waline({
  el: '#waline',
  serverURL: 'https://blog-api-n81h9yupz-aruis.vercel.app',
  pageSize: '15',
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/">实用技巧</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E6%8A%80%E5%B7%A7/">工具技巧</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%96%87%E8%89%BA%E4%B8%AD%E5%B9%B4/">文艺中年</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B8%B8%E8%AE%B0/">游记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/">程序人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E7%9B%B8%E5%85%B3/">设计相关</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6%E6%97%A5%E8%AE%B0/">读书日记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 15px;">前端</a> <a href="/tags/Geb/" style="font-size: 15px;">Geb</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 15px;">代理</a> <a href="/tags/gradle/" style="font-size: 15px;">gradle</a> <a href="/tags/%E4%B9%B1%E7%A0%81/" style="font-size: 15px;">乱码</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 15px;">IntelliJ IDEA</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/IDEA/" style="font-size: 15px;">IDEA</a> <a href="/tags/MySQL/" style="font-size: 15px;">MySQL</a> <a href="/tags/%E6%95%99%E8%82%B2%E5%AD%90%E5%A5%B3/" style="font-size: 15px;">教育子女</a> <a href="/tags/PostgreSQL/" style="font-size: 15px;">PostgreSQL</a> <a href="/tags/cas/" style="font-size: 15px;">cas</a> <a href="/tags/Vert-x/" style="font-size: 15px;">Vert.x</a> <a href="/tags/nginx/" style="font-size: 15px;">nginx</a> <a href="/tags/https/" style="font-size: 15px;">https</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">深度学习</a> <a href="/tags/GitHub/" style="font-size: 15px;">GitHub</a> <a href="/tags/Cordova/" style="font-size: 15px;">Cordova</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/FastDFS/" style="font-size: 15px;">FastDFS</a> <a href="/tags/vue/" style="font-size: 15px;">vue</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/groovy/" style="font-size: 15px;">groovy</a> <a href="/tags/ios/" style="font-size: 15px;">ios</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/WEB/" style="font-size: 15px;">WEB</a> <a href="/tags/Kotlin/" style="font-size: 15px;">Kotlin</a> <a href="/tags/UI%E8%AE%BE%E8%AE%A1/" style="font-size: 15px;">UI设计</a> <a href="/tags/RESTful/" style="font-size: 15px;">RESTful</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/tomcat/" style="font-size: 15px;">tomcat</a> <a href="/tags/ubuntu/" style="font-size: 15px;">ubuntu</a> <a href="/tags/contributors/" style="font-size: 15px;">contributors</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/%E7%90%86%E8%AE%BA/" style="font-size: 15px;">理论</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 15px;">运维</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2024/02/20/install-and-use-asitop/">基于命令的 macOS 资源监控工具 asitop，可以监控CPU、GPU功耗</a></li><li class="post-list-item"><a class="post-list-link" href="/2024/02/01/install-timescaledb-as-extension/">给已存在 PostgreSQL 服务安装 TimescaleDB 插件</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/29/cnn-animal10-try-1/">简单训练一下Animal-10的数据（第一版，精度很拉垮）</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/28/cnn-cifar10-try-5-data-augmentation/">通过Data Augmentation把CIFAR10的训练精度提升到89%</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/21/cnn-cifar10-try-4-BatchNormalization/">通过BatchNormalization把CIFAR10的训练精度提升到85%</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/18/disable-metal-gpu-on-apple-silicon/">在Apple Silicon上关闭M1的GPU，仅用CPU进行Tensorflow训练</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/15/cnn-cifar10-try-3-deep/">通过加深网络把CIFAR10的训练精度提升到80%</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/14/cnn-cifar10-try-2/">使用简单的CNN训练CIFAR10，理解padding='same'的含义</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/12/cnn-cifar10/">普普通通的CNN训练CIFAR-10</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/11/kill-pid-in-windows/">在windows里杀进程，遭遇提示：没有此任务的实例在运行</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://getaoning.com" title="葛涛宁的博客" target="_blank">葛涛宁的博客</a><ul></ul><a href="https://www.tony-bro.com" title="TONY'S TOY BLOG" target="_blank">TONY'S TOY BLOG</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2024 <a href="/." rel="nofollow">槛槛之间，点点滴滴.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>