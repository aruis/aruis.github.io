<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>通过Data Augmentation把CIFAR10的训练精度提升到89% | 槛槛之间，点点滴滴</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="/css/dark.css?v=1.0.0"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/normalize.css/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/pure-min.min.css"><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/npm/purecss/build/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.jsdelivr.net/npm/jquery/dist/jquery.min.js"></script><link rel="icon" mask="" sizes="any" href="/favicon.ico"><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"><link rel="alternate" type="application/atom+xml" href="/atom.xml"><script src="https://www.googletagmanager.com/gtag/js?id=UA-123510178-1" async></script><script>window.dataLayer = window.dataLayer || [];
function gtag(){dataLayer.push(arguments);}
gtag('js', new Date());
gtag('config', 'UA-123510178-1');
</script><script>var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = 'https://hm.baidu.com/hm.js?' + 'cb57d6270614f565f1d62009fe3ef740';
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
  })();
</script><script type="text/javascript" src="//cdn.jsdelivr.net/npm/clipboard/dist/clipboard.min.js"></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.js"></script><link rel="stylesheet" href="//cdn.jsdelivr.net/gh/codeseven/toastr/build/toastr.min.css"><div class="darkmode-toggle">🌓</div><script>var prefersDarkMode = window.matchMedia('(prefers-color-scheme: dark)');
var toggle = document.querySelector('.darkmode-toggle');
var html = document.querySelector('html');

html.dataset.dark = localStorage.dark || prefersDarkMode.matches;

toggle.addEventListener('click', () => {
localStorage.dark = !(html.dataset.dark == 'true');
html.dataset.dark = localStorage.dark;
});</script><meta name="generator" content="Hexo 6.1.0"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">通过Data Augmentation把CIFAR10的训练精度提升到89%</h1><a id="logo" href="/.">槛槛之间，点点滴滴</a><p class="description">牧云踏歌的博客，企图做个槛外人，但其实不过在槛槛之间徘徊罢了</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">通过Data Augmentation把CIFAR10的训练精度提升到89%</h1><div class="post-meta">2022-04-28<span> | </span><span class="category"><a href="/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/">程序人生</a></span></div><a class="disqus-comment-count" href="/2022/04/28/cnn-cifar10-try-5-data-augmentation/#vcomment"><span class="waline-comment-count" id="/2022/04/28/cnn-cifar10-try-5-data-augmentation/"></span><span> 条评论</span></a><div class="post-content"><p>我们先来回顾一下上一次的训练结果：</p>
<p><img src="/media/CleanShot-2022-04-28-10.42.58.png" alt="CleanShot-2022-04-28-10.42.58"></p>
<p>可以看到在训练不到<code>20</code>批的时候，训练精度就与测试精度分道扬镳了。这算是一种过拟合。目前我们手上的工具箱也就剩<code>数据增强</code>还没用了。理论上<code>数据增强</code>可以弥补<code>训练集</code>太小的问题，从而缓解<code>过拟合</code>的现象。实话说，在实际操作中，这种方法已经被检验过有效了。但是总给人一种<code>用一种机器去欺骗另一种机器</code>的感觉，我个人觉得，<code>机械化</code>的<code>数据增强</code>应该早晚被更优秀的训练模型所取代。</p>
<p>闲话少说，我们来看下最终的效果：</p>
<p><img src="/media/CleanShot-2022-04-28-10.52.00.png" alt="CleanShot-2022-04-28-10.52.00"></p>
<p>这是训练了<code>100</code>批的效果（足足花费了我43分49秒），前几次的训练都是到<code>50</code>批我就觉得差不多了。这次 一开始我也是用的<code>50</code>，但是当我发现<code>训练精度</code>被<code>验证精度</code>咬得死死的时候，我就又训练了<code>100</code>批的，也就是上面的结果。</p>
<p>可以看到，虽然从<code>40</code>批开始，训练进步的幅度就开始放缓了，但是整个训练还一直向好的方向上前进，<code>过拟合</code>现象也得到了抑制。基本在<code>100</code>批的时候，我们已经有了一个<code>验证精度</code>在<code>88%</code>～<code>89%</code>的模型，总的来说还是有效果的。</p>
<p>下面看下<code>数据增强</code>的核心代码：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras.preprocessing.image <span class="keyword">import</span> ImageDataGenerator</span><br><span class="line"></span><br><span class="line">datagen = ImageDataGenerator(</span><br><span class="line">        featurewise_center=<span class="literal">False</span>,  <span class="comment"># 将整个数据集的均值设为0</span></span><br><span class="line">        samplewise_center=<span class="literal">False</span>,  <span class="comment"># 将每个样本的均值设为0</span></span><br><span class="line">        featurewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># 将输入除以整个数据集的标准差</span></span><br><span class="line">        samplewise_std_normalization=<span class="literal">False</span>,  <span class="comment"># 将输入除以其标准差</span></span><br><span class="line">        zca_whitening=<span class="literal">False</span>,  <span class="comment"># 运用 ZCA 白化</span></span><br><span class="line">        zca_epsilon=<span class="number">1e-06</span>,  <span class="comment"># ZCA 白化的 epsilon值</span></span><br><span class="line">        rotation_range=<span class="number">0</span>,  <span class="comment"># 随机旋转图像范围 (角度, 0 to 180)</span></span><br><span class="line">        <span class="comment"># 随机水平移动图像 (总宽度的百分比)</span></span><br><span class="line">        width_shift_range=<span class="number">0.1</span>,</span><br><span class="line">        <span class="comment"># 随机垂直移动图像 (总高度的百分比)</span></span><br><span class="line">        height_shift_range=<span class="number">0.1</span>,</span><br><span class="line">        shear_range=<span class="number">0.</span>,  <span class="comment"># 设置随机裁剪范围</span></span><br><span class="line">        zoom_range=<span class="number">0.</span>,  <span class="comment"># 设置随机放大范围</span></span><br><span class="line">        channel_shift_range=<span class="number">0.</span>,  <span class="comment"># 设置随机通道切换的范围</span></span><br><span class="line">        <span class="comment"># 设置填充输入边界之外的点的模式</span></span><br><span class="line">        fill_mode=<span class="string">&#x27;nearest&#x27;</span>,</span><br><span class="line">        cval=<span class="number">0.</span>,  <span class="comment"># 在 fill_mode = &quot;constant&quot; 时使用的值</span></span><br><span class="line">        horizontal_flip=<span class="literal">True</span>,  <span class="comment"># 随机水平翻转图像</span></span><br><span class="line">        vertical_flip=<span class="literal">False</span>,  <span class="comment"># 随机垂直翻转图像</span></span><br><span class="line">        <span class="comment"># 设置缩放因子 (在其他转换之前使用)</span></span><br><span class="line">        rescale=<span class="literal">None</span>,</span><br><span class="line">        <span class="comment"># 设置将应用于每一个输入的函数</span></span><br><span class="line">        preprocessing_function=<span class="literal">None</span>,</span><br><span class="line">        <span class="comment"># 图像数据格式，&quot;channels_first&quot; 或 &quot;channels_last&quot; 之一</span></span><br><span class="line">        data_format=<span class="literal">None</span>,</span><br><span class="line">        <span class="comment"># 保留用于验证的图像比例（严格在0和1之间）</span></span><br><span class="line">        validation_split=<span class="number">0.0</span>)</span><br><span class="line"></span><br><span class="line">datagen.fit(train_images)</span><br></pre></td></tr></table></figure>

<p>上面的代码基本上就是照抄<code>keras</code>官方文档的<a href="https://keras.io/zh/examples/cifar10_cnn/">一节</a>，不过我们的模型与文档还是有很大不同，毕竟是我们一步步探索出来的，最终模型代码如下：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> layers</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> models</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">model = models.Sequential()</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>, input_shape=(<span class="number">32</span>, <span class="number">32</span>, <span class="number">3</span>),padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Conv2D(<span class="number">32</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.2</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Conv2D(<span class="number">64</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.3</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Conv2D(<span class="number">128</span>, (<span class="number">3</span>, <span class="number">3</span>), activation=<span class="string">&#x27;relu&#x27;</span>,padding=<span class="string">&#x27;same&#x27;</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.MaxPooling2D((<span class="number">2</span>, <span class="number">2</span>)))</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line"></span><br><span class="line">model.add(layers.Flatten())</span><br><span class="line">model.add(layers.Dropout(<span class="number">0.4</span>))</span><br><span class="line">model.add(layers.BatchNormalization())</span><br><span class="line">model.add(layers.Dense(<span class="number">10</span>, activation=<span class="string">&#x27;softmax&#x27;</span>))</span><br><span class="line"></span><br><span class="line">model.summary()</span><br></pre></td></tr></table></figure>

<p>有了<code>数据增强</code>后，我们训练模型的代码要稍加改动：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">model.<span class="built_in">compile</span>(optimizer=<span class="string">&#x27;Adam&#x27;</span>,</span><br><span class="line">              loss=<span class="string">&#x27;categorical_crossentropy&#x27;</span>,</span><br><span class="line">              metrics=[<span class="string">&#x27;accuracy&#x27;</span>])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">history = model.fit(datagen.flow( train_images, train_labels,batch_size=<span class="number">64</span>), epochs=<span class="number">100</span>,validation_data=(test_images, test_labels))</span><br></pre></td></tr></table></figure>

<p>最后再说一下，我用的<code>optimizer</code>（优化器）是<code>Adam</code>，跟上面提到的<code>keras</code><a href="https://keras.io/zh/examples/cifar10_cnn/">文档</a>里用的<code>RMSprop</code>还是有区别的。根据我实际测试下来，<code>Adam</code>的学习速度还是要好于<code>RMSprop</code>的。</p>
<p><img src="/media/CleanShot-2022-04-28-13.25.26.png" alt="CleanShot-2022-04-28-13.25.26"></p>
<p>左图是<code>RMSprop</code>，右图是<code>Adam</code>（也就是我们上面实际在跑的结果）。通过对比我们可以看出来，<code>10</code>批之后，<code>Adam</code>的<code>训练精度</code>就达到了<code>75%</code>，而<code>RMSprop</code>的<code>训练</code>精度还仅有<code>64%</code>。所以把<code>Adam</code>作为一个默认选项会是一个挺好的选择，这也是我们在前几次训练中使用的。</p>
</div><div class="post-copyright"><script type="text/javascript" src="/js/copyright.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copyright.css"><p><span>本文标题：</span>通过Data Augmentation把CIFAR10的训练精度提升到89%</p><p><span>文章作者：</span>牧云踏歌</p><p><span>发布时间：</span>2022-04-28</p><p><span>最后更新：</span>2022-04-28</p><p><span>原始链接：</span><a href="/2022/04/28/cnn-cifar10-try-5-data-augmentation/">http://www.kankanzhijian.com/2022/04/28/cnn-cifar10-try-5-data-augmentation/</a><span class="copy-path"><i class="fa fa-clipboard" data-clipboard-text="http://www.kankanzhijian.com/2022/04/28/cnn-cifar10-try-5-data-augmentation/"></i></span></p><p><span>版权声明：</span>本博客文章均系本人原创，转载请注名出处</p></div><br><div class="tags"><a href="/tags/Keras/"><i class="fa fa-tag"></i>Keras</a><a href="/tags/DeepLearning/"><i class="fa fa-tag"></i>DeepLearning</a></div><div class="post-nav"><a class="next" href="/2022/04/21/cnn-cifar10-try-4-BatchNormalization/">通过BatchNormalization把CIFAR10的训练精度提升到85%</a></div><div id="waline"></div><script src="https://cdn.jsdelivr.net/npm/@waline/client"></script><script>Waline({
  el: '#waline',
  serverURL: 'https://blog-api-n81h9yupz-aruis.vercel.app',
  pageSize: '15',
})
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><div class="search-form"><input id="local-search-input" placeholder="Search" type="text" name="q" results="0"/><div id="local-search-result"></div></div></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%AE%9E%E7%94%A8%E6%8A%80%E5%B7%A7/">实用技巧</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E5%B7%A5%E5%85%B7%E6%8A%80%E5%B7%A7/">工具技巧</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%96%87%E8%89%BA%E4%B8%AD%E5%B9%B4/">文艺中年</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E6%B8%B8%E8%AE%B0/">游记</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E7%A8%8B%E5%BA%8F%E4%BA%BA%E7%94%9F/">程序人生</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AE%BE%E8%AE%A1%E7%9B%B8%E5%85%B3/">设计相关</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%AF%BB%E4%B9%A6%E6%97%A5%E8%AE%B0/">读书日记</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/%E5%89%8D%E7%AB%AF/" style="font-size: 15px;">前端</a> <a href="/tags/Geb/" style="font-size: 15px;">Geb</a> <a href="/tags/Java/" style="font-size: 15px;">Java</a> <a href="/tags/%E4%BB%A3%E7%90%86/" style="font-size: 15px;">代理</a> <a href="/tags/gradle/" style="font-size: 15px;">gradle</a> <a href="/tags/%E4%B9%B1%E7%A0%81/" style="font-size: 15px;">乱码</a> <a href="/tags/IntelliJ-IDEA/" style="font-size: 15px;">IntelliJ IDEA</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/IDEA/" style="font-size: 15px;">IDEA</a> <a href="/tags/MySQL/" style="font-size: 15px;">MySQL</a> <a href="/tags/%E6%95%99%E8%82%B2%E5%AD%90%E5%A5%B3/" style="font-size: 15px;">教育子女</a> <a href="/tags/PostgreSQL/" style="font-size: 15px;">PostgreSQL</a> <a href="/tags/cas/" style="font-size: 15px;">cas</a> <a href="/tags/Vert-x/" style="font-size: 15px;">Vert.x</a> <a href="/tags/nginx/" style="font-size: 15px;">nginx</a> <a href="/tags/https/" style="font-size: 15px;">https</a> <a href="/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/" style="font-size: 15px;">深度学习</a> <a href="/tags/GitHub/" style="font-size: 15px;">GitHub</a> <a href="/tags/Cordova/" style="font-size: 15px;">Cordova</a> <a href="/tags/Docker/" style="font-size: 15px;">Docker</a> <a href="/tags/FastDFS/" style="font-size: 15px;">FastDFS</a> <a href="/tags/vue/" style="font-size: 15px;">vue</a> <a href="/tags/Spring/" style="font-size: 15px;">Spring</a> <a href="/tags/groovy/" style="font-size: 15px;">groovy</a> <a href="/tags/ios/" style="font-size: 15px;">ios</a> <a href="/tags/Mac/" style="font-size: 15px;">Mac</a> <a href="/tags/WEB/" style="font-size: 15px;">WEB</a> <a href="/tags/Kotlin/" style="font-size: 15px;">Kotlin</a> <a href="/tags/UI%E8%AE%BE%E8%AE%A1/" style="font-size: 15px;">UI设计</a> <a href="/tags/RESTful/" style="font-size: 15px;">RESTful</a> <a href="/tags/git/" style="font-size: 15px;">git</a> <a href="/tags/tomcat/" style="font-size: 15px;">tomcat</a> <a href="/tags/ubuntu/" style="font-size: 15px;">ubuntu</a> <a href="/tags/contributors/" style="font-size: 15px;">contributors</a> <a href="/tags/vim/" style="font-size: 15px;">vim</a> <a href="/tags/%E7%90%86%E8%AE%BA/" style="font-size: 15px;">理论</a> <a href="/tags/Keras/" style="font-size: 15px;">Keras</a> <a href="/tags/DeepLearning/" style="font-size: 15px;">DeepLearning</a> <a href="/tags/%E8%BF%90%E7%BB%B4/" style="font-size: 15px;">运维</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2022/04/28/cnn-cifar10-try-5-data-augmentation/">通过Data Augmentation把CIFAR10的训练精度提升到89%</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/21/cnn-cifar10-try-4-BatchNormalization/">通过BatchNormalization把CIFAR10的训练精度提升到85%</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/18/disable-metal-gpu-on-apple-silicon/">在Apple Silicon上关闭M1的GPU，仅用CPU进行Tensorflow训练</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/15/cnn-cifar10-try-3-deep/">通过加深网络把CIFAR10的训练精度提升到80%</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/14/cnn-cifar10-try-2/">使用简单的CNN训练CIFAR10，理解padding='same'的含义</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/12/cnn-cifar10/">普普通通的CNN训练CIFAR-10</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/11/kill-pid-in-windows/">在windows里杀进程，遭遇提示：没有此任务的实例在运行</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/04/01/use-vgg16-at-cifar10/">使用VGG16训练CIFAR-10的一次失败记录</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/31/becoming-a-batter-programmer/">《程序员的38堂成长课》读后小记</a></li><li class="post-list-item"><a class="post-list-link" href="/2022/03/30/power-four-level/">能力的四个阶段</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="https://getaoning.com" title="葛涛宁的博客" target="_blank">葛涛宁的博客</a><ul></ul><a href="https://www.tony-bro.com" title="TONY'S TOY BLOG" target="_blank">TONY'S TOY BLOG</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2022 <a href="/." rel="nofollow">槛槛之间，点点滴滴.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=1.0.0" async></script><script type="text/javascript" src="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=1.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.jsdelivr.net/gh/fancyapps/fancybox/dist/jquery.fancybox.min.css"><link rel="stylesheet" type="text/css" href="/css/search.css?v=1.0.0"><script type="text/javascript" src="/js/search.js?v=1.0.0"></script><script>var search_path = 'search.xml';
if (search_path.length == 0) {
   search_path = 'search.xml';
}
var path = '/' + search_path;
searchFunc(path, 'local-search-input', 'local-search-result');
</script><script type="text/javascript" src="/js/copycode.js" successtext="复制成功!"></script><link rel="stylesheet" type="text/css" href="/css/copycode.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=1.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=1.0.0"></script></div></body></html>